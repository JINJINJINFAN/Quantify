# -*- coding: utf-8 -*-
# data_loader.py
import requests
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from dotenv import load_dotenv
import os
import time
import random
from config import *
import pytz  # æ·»åŠ æ—¶åŒºæ”¯æŒ
import inspect
from typing import Dict, List, Optional, Any

load_dotenv()  # åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆä»…ç”¨äºæ•æ„Ÿå‚æ•°ï¼‰

class TimezoneHandler:
    """ç»Ÿä¸€å¤„ç†æ—¶åŒºè½¬æ¢çš„ç±»"""
    
    def __init__(self):
        # è®¾ç½®é¦™æ¸¯æ—¶åŒº
        self.hk_tz = pytz.timezone('Asia/Hong_Kong')
        self.utc_tz = pytz.UTC
        
    def parse_datetime(self, date_str, default_hour=0, default_minute=0, default_second=0):
        """
        è§£ææ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²ï¼Œç»Ÿä¸€è½¬æ¢ä¸ºé¦™æ¸¯æ—¶åŒº
        
        Args:
            date_str: æ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²ï¼Œæ”¯æŒæ ¼å¼ï¼š
                     - 'YYYY-MM-DD'
                     - 'YYYY-MM-DD HH:MM:SS'
            default_hour: é»˜è®¤å°æ—¶ï¼ˆå½“åªæœ‰æ—¥æœŸæ—¶ï¼‰
            default_minute: é»˜è®¤åˆ†é’Ÿï¼ˆå½“åªæœ‰æ—¥æœŸæ—¶ï¼‰
            default_second: é»˜è®¤ç§’æ•°ï¼ˆå½“åªæœ‰æ—¥æœŸæ—¶ï¼‰
            
        Returns:
            datetime: é¦™æ¸¯æ—¶åŒºçš„datetimeå¯¹è±¡
        """
        try:
            if " " in date_str:  # åŒ…å«æ—¶é—´ä¿¡æ¯
                dt = datetime.strptime(date_str, "%Y-%m-%d %H:%M:%S")
            else:  # åªæœ‰æ—¥æœŸä¿¡æ¯
                dt = datetime.strptime(date_str, "%Y-%m-%d")
                dt = dt.replace(hour=default_hour, minute=default_minute, second=default_second)
            
            # è®¾ç½®ä¸ºé¦™æ¸¯æ—¶åŒº
            return self.hk_tz.localize(dt)
        except ValueError as e:
            raise ValueError(f"æ—¥æœŸæ ¼å¼é”™è¯¯: {date_str}, é”™è¯¯: {e}")
    
    def to_utc_timestamp(self, hk_datetime):
        """
        å°†é¦™æ¸¯æ—¶åŒºçš„datetimeè½¬æ¢ä¸ºUTCæ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
        
        Args:
            hk_datetime: é¦™æ¸¯æ—¶åŒºçš„datetimeå¯¹è±¡
            
        Returns:
            int: UTCæ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
        """
        if hk_datetime.tzinfo is None:
            hk_datetime = self.hk_tz.localize(hk_datetime)
        
        utc_datetime = hk_datetime.astimezone(self.utc_tz)
        return int(utc_datetime.timestamp() * 1000)
    
    def from_utc_timestamp(self, utc_timestamp_ms):
        """
        å°†UTCæ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰è½¬æ¢ä¸ºé¦™æ¸¯æ—¶åŒºçš„datetime
        
        Args:
            utc_timestamp_ms: UTCæ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
            
        Returns:
            datetime: é¦™æ¸¯æ—¶åŒºçš„datetimeå¯¹è±¡
        """
        utc_datetime = datetime.fromtimestamp(utc_timestamp_ms / 1000, self.utc_tz)
        return utc_datetime.astimezone(self.hk_tz)
    
    def get_current_hk_time(self):
        """
        è·å–å½“å‰é¦™æ¸¯æ—¶é—´
        
        Returns:
            datetime: å½“å‰é¦™æ¸¯æ—¶é—´
        """
        return datetime.now(self.hk_tz)
    
    def get_current_utc_timestamp(self):
        """
        è·å–å½“å‰UTCæ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
        
        Returns:
            int: å½“å‰UTCæ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
        """
        return int(datetime.now(self.utc_tz).timestamp() * 1000)
    
    def validate_time_range(self, start_timestamp, end_timestamp, max_days_back=365):
        """
        éªŒè¯æ—¶é—´èŒƒå›´çš„åˆç†æ€§
        
        Args:
            start_timestamp: å¼€å§‹æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
            end_timestamp: ç»“æŸæ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
            max_days_back: æœ€å¤§å›çœ‹å¤©æ•°
            
        Returns:
            tuple: (è°ƒæ•´åçš„å¼€å§‹æ—¶é—´æˆ³, è°ƒæ•´åçš„ç»“æŸæ—¶é—´æˆ³)
        """
        current_timestamp = self.get_current_utc_timestamp()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æœªæ¥æ—¶é—´
        if start_timestamp > current_timestamp or end_timestamp > current_timestamp:
            print(f"æ£€æµ‹åˆ°æœªæ¥æ—¶é—´èŒƒå›´ï¼Œè°ƒæ•´ä¸ºè¿‡å»{max_days_back}å¤©")
            end_timestamp = current_timestamp
            start_timestamp = end_timestamp - (max_days_back * 24 * 60 * 60 * 1000)
        
        # æ£€æŸ¥æ—¶é—´èŒƒå›´æ˜¯å¦åˆç†
        if end_timestamp <= start_timestamp:
            raise ValueError("ç»“æŸæ—¶é—´å¿…é¡»å¤§äºå¼€å§‹æ—¶é—´")
        
        # æ£€æŸ¥æ—¶é—´èŒƒå›´æ˜¯å¦è¿‡é•¿
        max_range_ms = max_days_back * 24 * 60 * 60 * 1000
        if end_timestamp - start_timestamp > max_range_ms:
            print(f"æ—¶é—´èŒƒå›´è¿‡é•¿ï¼Œè°ƒæ•´ä¸º{max_days_back}å¤©")
            start_timestamp = end_timestamp - max_range_ms
        
        return start_timestamp, end_timestamp
    
    def format_datetime_for_display(self, dt):
        """
        æ ¼å¼åŒ–datetimeç”¨äºæ˜¾ç¤º
        
        Args:
            dt: datetimeå¯¹è±¡
            
        Returns:
            str: æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸²
        """
        if dt.tzinfo is None:
            dt = self.hk_tz.localize(dt)
        elif dt.tzinfo != self.hk_tz:
            dt = dt.astimezone(self.hk_tz)
        
        return dt.strftime('%Y-%m-%d %H:%M:%S')

class DataLoader:
    def __init__(self, timeframe="1h"):
        self.symbol = TRADING_CONFIG["SYMBOL"]
        self.timeframe = timeframe
        
        # åˆå§‹åŒ–æ—¶åŒºå¤„ç†å™¨
        self.tz_handler = TimezoneHandler()
        
        # æ”¯æŒçš„æ—¶é—´çº§åˆ«æ˜ å°„
        self.timeframe_mapping = {
            "MIN5": "5m",
            "MIN15": "15m",
            "MIN30": "30m", 
            "HOUR1": "1h",
            "HOUR2": "2h",
            "HOUR4": "4h",
            "HOUR8": "8h",
            "DAY1": "1d",
        }
        
        # ä»é…ç½®ä¸­è·å–APIç«¯ç‚¹
        from config import BINANCE_API_CONFIG
        # ä¿®å¤API URL - æ„å»ºæ­£ç¡®çš„åˆçº¦API URL
        api_url = f"{BINANCE_API_CONFIG['MAINNET']['BASE_URL']}/fapi/{BINANCE_API_CONFIG['MAINNET']['API_VERSION']}"
        
        # ä½¿ç”¨åˆçº¦APIï¼ˆä»…ç”Ÿäº§ç¯å¢ƒï¼‰
        self.api_endpoints = [
            api_url
        ]
        
        # å¼ºåˆ¶ä½¿ç”¨çœŸå®æ•°æ®ï¼Œä¸ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        self.use_mock_data = False
        # è·³è¿‡ç½‘ç»œè¿æ¥æµ‹è¯•ï¼Œå…è®¸ç¦»çº¿æ¨¡å¼
        try:
            self._test_connection()
        except Exception as e:
            print(f"ç½‘ç»œè¿æ¥æµ‹è¯•å¤±è´¥ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®: {e}")
            self.use_mock_data = True
        
        # è´ªå©ªæŒ‡æ•°ç¼“å­˜
        self.fear_greed_cache = {}
        self.fear_greed_cache_timeout = 3600  # 1å°æ—¶ç¼“å­˜
        
        # ===== æ•°æ®ç¼“å­˜ç³»ç»Ÿ =====
        self._cache = {}  # ç¼“å­˜å­˜å‚¨
        self._cache_timestamps = {}  # ç¼“å­˜æ—¶é—´æˆ³
        self._cache_timeout = 300  # ç¼“å­˜è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        self._max_cache_size = 1000  # æœ€å¤§ç¼“å­˜æ•°æ®æ¡æ•°
        self._last_update_time = {}  # æœ€åæ›´æ–°æ—¶é—´
        self._min_update_interval = 30  # æœ€å°æ›´æ–°é—´éš”ï¼ˆç§’ï¼‰
    
    def _generate_cache_key(self, start_date, end_date):
        """ç”Ÿæˆç¼“å­˜é”® - æ”¯æŒç²¾ç¡®æ—¶é—´"""
        # æ ‡å‡†åŒ–æ—¶é—´æ ¼å¼ï¼Œç¡®ä¿ç¼“å­˜é”®çš„ä¸€è‡´æ€§
        def normalize_time(time_str):
            """æ ‡å‡†åŒ–æ—¶é—´å­—ç¬¦ä¸²ï¼Œå»é™¤åˆ†é’Ÿã€ç§’å’Œæ¯«ç§’ï¼Œä¿ç•™åˆ°å°æ—¶ç²¾åº¦"""
            if ' ' in time_str:
                # åŒ…å«æ—¶é—´ä¿¡æ¯ï¼Œä¿ç•™åˆ°å°æ—¶
                date_part, time_part = time_str.split(' ')
                if ':' in time_part:
                    # å¦‚æœæœ‰å°æ—¶ä¿¡æ¯ï¼Œä¿ç•™åˆ°å°æ—¶
                    if time_part.count(':') >= 1:
                        # æœ‰å°æ—¶ä¿¡æ¯ï¼Œå»é™¤åˆ†é’Ÿå’Œç§’
                        time_part = time_part.split(':')[0] + ':00:00'
                    return f"{date_part} {time_part}"
                else:
                    # åªæœ‰æ—¥æœŸï¼Œæ·»åŠ é»˜è®¤æ—¶é—´
                    return f"{date_part} 00:00:00"
            else:
                # åªæœ‰æ—¥æœŸï¼Œæ·»åŠ é»˜è®¤æ—¶é—´
                return f"{time_str} 00:00:00"
        
        normalized_start = normalize_time(start_date)
        normalized_end = normalize_time(end_date)
        
        return f"{self.symbol}_{self.timeframe}_{normalized_start}_{normalized_end}"
    
    def _is_cache_valid(self, cache_key):
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if cache_key not in self._cache or cache_key not in self._cache_timestamps:
            return False
        
        current_time = time.time()
        cache_time = self._cache_timestamps[cache_key]
        
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¶…æ—¶
        if current_time - cache_time > self._cache_timeout:
            return False
        
        return True
    
    def _can_update_cache(self, cache_key):
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥æ›´æ–°ç¼“å­˜"""
        if cache_key not in self._last_update_time:
            return True
        
        current_time = time.time()
        last_update = self._last_update_time[cache_key]
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å°æ›´æ–°é—´éš”
        return current_time - last_update >= self._min_update_interval
    
    def _update_cache(self, cache_key, data):
        """æ›´æ–°ç¼“å­˜"""
        self._cache[cache_key] = data
        self._cache_timestamps[cache_key] = time.time()
        self._last_update_time[cache_key] = time.time()
        
        # æ¸…ç†è¿‡æœŸç¼“å­˜
        self._cleanup_cache()
    
    def _cleanup_cache(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        current_time = time.time()
        expired_keys = []
        
        for key, timestamp in self._cache_timestamps.items():
            if current_time - timestamp > self._cache_timeout:
                expired_keys.append(key)
        
        for key in expired_keys:
            del self._cache[key]
            del self._cache_timestamps[key]
            if key in self._last_update_time:
                del self._last_update_time[key]
        
        # å¦‚æœç¼“å­˜æ•°æ®è¿‡å¤šï¼Œåˆ é™¤æœ€æ—§çš„æ•°æ®
        if len(self._cache) > self._max_cache_size:
            sorted_keys = sorted(self._cache_timestamps.items(), key=lambda x: x[1])
            keys_to_remove = [key for key, _ in sorted_keys[:len(self._cache) - self._max_cache_size]]
            
            for key in keys_to_remove:
                del self._cache[key]
                del self._cache_timestamps[key]
                if key in self._last_update_time:
                    del self._last_update_time[key]
    
    def _get_cached_data(self, cache_key):
        """è·å–ç¼“å­˜æ•°æ®"""
        return self._cache.get(cache_key)
    
    def _incremental_update(self, cached_data, new_data):
        """å¢é‡æ›´æ–°æ•°æ®"""
        if cached_data is None or new_data is None:
            return new_data
        
        # åˆå¹¶æ•°æ®ï¼Œé¿å…é‡å¤
        cached_df = pd.DataFrame(cached_data)
        new_df = pd.DataFrame(new_data)
        
        # æŒ‰æ—¶é—´æˆ³å»é‡ï¼Œä¿ç•™æœ€æ–°çš„æ•°æ®
        combined_df = pd.concat([cached_df, new_df], ignore_index=True)
        combined_df = combined_df.drop_duplicates(subset=[0], keep='last')  # 0æ˜¯æ—¶é—´æˆ³åˆ—
        combined_df = combined_df.sort_values(by=[0])  # æŒ‰æ—¶é—´æˆ³æ’åº
        
        return combined_df.values.tolist()
    
    def _convert_to_dataframe(self, cached_data):
        """å°†ç¼“å­˜æ•°æ®è½¬æ¢ä¸ºDataFrame"""
        if not cached_data:
            return pd.DataFrame()
        
        # æ£€æŸ¥æ•°æ®æ ¼å¼å¹¶åˆ›å»ºDataFrame
        if len(cached_data[0]) == 6:
            # åŸå§‹æ ¼å¼ï¼štimestamp, open, high, low, close, volume
            df = pd.DataFrame(
                cached_data,
                columns=["timestamp", "open", "high", "low", "close", "volume"]
            )
            
            # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºdatetime
            df["datetime"] = pd.to_datetime(df["timestamp"], unit="ms", utc=True).dt.tz_convert(self.tz_handler.hk_tz)
            df = df.set_index("datetime").drop(columns=["timestamp"])
            
        elif len(cached_data[0]) == 7:
            # ç¼“å­˜æ ¼å¼ï¼šdatetime, timestamp, open, high, low, close, volume
            df = pd.DataFrame(
                cached_data,
                columns=["datetime", "timestamp", "open", "high", "low", "close", "volume"]
            )
            
            # å¤„ç†datetimeåˆ—
            if df["datetime"].dtype == 'object':
                df["datetime"] = pd.to_datetime(df["datetime"])
            
            # è®¾ç½®ç´¢å¼•
            df = df.set_index("datetime").drop(columns=["timestamp"])
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ç¼“å­˜æ•°æ®æ ¼å¼ï¼Œåˆ—æ•°: {len(cached_data[0])}")
        
        return df.astype(float)
    
    def set_cache_config(self, cache_timeout=None, min_update_interval=None, max_cache_size=None):
        """è®¾ç½®ç¼“å­˜é…ç½®"""
        if cache_timeout is not None:
            self._cache_timeout = cache_timeout
            print(f"ğŸ”„ ç¼“å­˜è¶…æ—¶æ—¶é—´è®¾ç½®ä¸º: {cache_timeout} ç§’")
        
        if min_update_interval is not None:
            self._min_update_interval = min_update_interval
            print(f"ğŸ”„ æœ€å°æ›´æ–°é—´éš”è®¾ç½®ä¸º: {min_update_interval} ç§’")
        
        if max_cache_size is not None:
            self._max_cache_size = max_cache_size
            print(f"ğŸ”„ æœ€å¤§ç¼“å­˜å¤§å°è®¾ç½®ä¸º: {max_cache_size} æ¡è®°å½•")
    
    def get_cache_stats(self):
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        current_time = time.time()
        stats = {
            'cache_size': len(self._cache),
            'cache_keys': list(self._cache.keys()),
            'cache_timeout': self._cache_timeout,
            'min_update_interval': self._min_update_interval,
            'max_cache_size': self._max_cache_size,
            'cache_info': {}
        }
        
        for key, timestamp in self._cache_timestamps.items():
            age = current_time - timestamp
            last_update = self._last_update_time.get(key, 0)
            last_update_age = current_time - last_update if last_update > 0 else 0
            
            stats['cache_info'][key] = {
                'age_seconds': age,
                'last_update_age_seconds': last_update_age,
                'is_valid': age < self._cache_timeout,
                'can_update': last_update_age >= self._min_update_interval
            }
        
        return stats
    
    def clear_cache(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        self._cache.clear()
        self._cache_timestamps.clear()
        self._last_update_time.clear()
        print("ğŸ—‘ï¸ æ‰€æœ‰ç¼“å­˜å·²æ¸…ç©º")
    
    def clear_expired_cache(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        before_count = len(self._cache)
        self._cleanup_cache()
        after_count = len(self._cache)
        cleared_count = before_count - after_count
        print(f"ğŸ§¹ æ¸…ç†äº† {cleared_count} ä¸ªè¿‡æœŸç¼“å­˜é¡¹")
    
    def cleanup(self):
        """æ¸…ç†æ•°æ®åŠ è½½å™¨èµ„æº"""
        try:
            print("ğŸ§¹ æ­£åœ¨æ¸…ç†æ•°æ®åŠ è½½å™¨èµ„æº...")
            
            # æ¸…ç†æ‰€æœ‰ç¼“å­˜
            cache_count = len(self._cache)
            self._cache.clear()
            self._cache_timestamps.clear()
            self._last_update_time.clear()
            
            # æ¸…ç†è´ªå©ªæŒ‡æ•°ç¼“å­˜
            fear_greed_count = len(self.fear_greed_cache)
            self.fear_greed_cache.clear()
            
            print(f"âœ… æ•°æ®åŠ è½½å™¨èµ„æºå·²æ¸…ç† (ç¼“å­˜: {cache_count}é¡¹, è´ªå©ªæŒ‡æ•°: {fear_greed_count}é¡¹)")
            return True
        except Exception as e:
            print(f"âŒ æ¸…ç†æ•°æ®åŠ è½½å™¨èµ„æºå¤±è´¥: {e}")
            return False
    
    def close(self):
        """å…³é—­æ•°æ®åŠ è½½å™¨"""
        try:
            print("ğŸ”’ æ­£åœ¨å…³é—­æ•°æ®åŠ è½½å™¨...")
            
            # æ¸…ç†èµ„æº
            self.cleanup()
            
            # å¦‚æœæœ‰ç½‘ç»œè¿æ¥ï¼Œå…³é—­å®ƒä»¬
            if hasattr(self, '_session') and self._session:
                self._session.close()
            
            print("âœ… æ•°æ®åŠ è½½å™¨å·²å…³é—­")
            return True
        except Exception as e:
            print(f"âŒ å…³é—­æ•°æ®åŠ è½½å™¨å¤±è´¥: {e}")
            return False
    
    def _test_connection(self):
        """æµ‹è¯•APIè¿æ¥"""
        print("ğŸ” æ­£åœ¨æµ‹è¯•APIè¿æ¥...")
        print(f"äº¤æ˜“å¯¹: {self.symbol}")
        print(f"â° æ—¶é—´çº§åˆ«: {self.timeframe}")
        
        try:
            endpoint = self.api_endpoints[0]
            print(f"ğŸ”— æµ‹è¯•APIç«¯ç‚¹: {endpoint}")
            response = requests.get(f"{endpoint}/time", timeout=5)
            if response.status_code == 200:
                print(f"æˆåŠŸè¿æ¥åˆ°Binanceåˆçº¦API: {endpoint}")
            else:
                print(f"åˆçº¦APIç«¯ç‚¹å“åº”å¼‚å¸¸: {response.status_code}")
                raise ConnectionError("åˆçº¦APIç«¯ç‚¹å“åº”å¼‚å¸¸")
        except Exception as e:
            print(f"APIç«¯ç‚¹è¿æ¥å¤±è´¥: {e}")
            raise ConnectionError("æ— æ³•è¿æ¥åˆ°Binanceåˆçº¦APIç«¯ç‚¹ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
    
    def _make_request(self, url, params=None, max_retries=3):
        """å‘é€HTTPè¯·æ±‚ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
        for attempt in range(max_retries):
            try:
                endpoint = self.api_endpoints[0]
                full_url = f"{endpoint}{url}"
                
                # æ˜¾ç¤ºå®Œæ•´çš„API URLï¼ˆä»…åœ¨è°ƒè¯•æ¨¡å¼ä¸‹ï¼‰
                if DEBUG_CONFIG["SHOW_API_URLS"]:
                    print(f"ğŸŒ è¯·æ±‚API URL: {full_url}")
                    if params:
                        print(f"ğŸ“‹ è¯·æ±‚å‚æ•°: {params}")
                
                # æ·»åŠ éšæœºå»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                time.sleep(random.uniform(0.2, 1.0))  # å¢åŠ å»¶è¿Ÿæ—¶é—´
                
                response = requests.get(full_url, params=params, timeout=30)  # å¢åŠ è¶…æ—¶æ—¶é—´
                
                if response.status_code == 200:
                    return response.json()
                elif response.status_code == 429:  # è¯·æ±‚é¢‘ç‡é™åˆ¶
                    print(f"âš  è¯·æ±‚é¢‘ç‡é™åˆ¶ï¼Œç­‰å¾…åé‡è¯•...")
                    time.sleep(5 + (2 ** attempt))  # å¢åŠ åŸºç¡€ç­‰å¾…æ—¶é—´
                    continue
                elif response.status_code == 503:  # æœåŠ¡ä¸å¯ç”¨
                    print(f"âš  æœåŠ¡ä¸å¯ç”¨ï¼Œç­‰å¾…åé‡è¯•...")
                    time.sleep(10 + (2 ** attempt))  # æ›´é•¿çš„ç­‰å¾…æ—¶é—´
                    continue
                else:
                    print(f"âš  APIå“åº”å¼‚å¸¸: {response.status_code}")
                    
            except requests.exceptions.RequestException as e:
                print(f"âš  è¯·æ±‚å¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(3 + (2 ** attempt))  # å¢åŠ åŸºç¡€ç­‰å¾…æ—¶é—´
                else:
                    print(f"æ‰€æœ‰é‡è¯•å¤±è´¥ï¼Œè·³è¿‡æ­¤è¯·æ±‚")
                    return None
        
        return None
    
    def _get_caller_info(self) -> str:
        """
        è·å–è°ƒç”¨æ ˆä¿¡æ¯ï¼Œæ˜¾ç¤ºæ˜¯å“ªä¸ªæ–¹æ³•è°ƒç”¨çš„æ•°æ®è·å–
        """
        try:
            # è·å–å½“å‰è°ƒç”¨æ ˆ
            stack = inspect.stack()
            
            # ä»æ ˆä¸­æŸ¥æ‰¾ç¬¬ä¸€ä¸ªéDataLoaderç±»çš„è°ƒç”¨è€…
            for frame_info in stack[1:]:  # è·³è¿‡å½“å‰æ–¹æ³•
                filename = frame_info.filename
                function = frame_info.function
                lineno = frame_info.lineno
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯DataLoaderç±»çš„æ–¹æ³•
                if not filename.endswith("data_loader.py") or function not in ["get_klines", "_get_caller_info"]:
                    # è·å–æ–‡ä»¶åï¼ˆå»æ‰è·¯å¾„ï¼‰
                    basename = os.path.basename(filename)
                    return f"{basename}:{function}:{lineno}"
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„è°ƒç”¨è€…ï¼Œè¿”å›å½“å‰ä¿¡æ¯
            return f"{os.path.basename(__file__)}:unknown"
        except Exception as e:
            return f"error:{str(e)}"
    
    def get_klines(self, start_date, end_date):
        """è·å–æŒ‡å®šæ—¶é—´èŒƒå›´çš„ K çº¿æ•°æ®ï¼ˆå¼€ç›˜ä»·ã€æ”¶ç›˜ä»·ç­‰ï¼‰- å¸¦ç¼“å­˜åŠŸèƒ½"""
        
        # è·å–è°ƒç”¨æ¥æºä¿¡æ¯
        caller_info = self._get_caller_info()
        
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = self._generate_cache_key(start_date, end_date)
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼ŒåŒ…å«è°ƒç”¨æ¥æº
        print(f"ğŸ” ç¼“å­˜é”®ç”Ÿæˆ: {cache_key}")
        print(f"ğŸ” åŸå§‹æ—¶é—´èŒƒå›´: {start_date} è‡³ {end_date}")
        print(f"ğŸ” è°ƒç”¨æ¥æº: {caller_info}")
        
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
        if self._is_cache_valid(cache_key):
            cached_data = self._get_cached_data(cache_key)
            if cached_data is not None:
                print(f"ğŸ“¦ ä½¿ç”¨ç¼“å­˜æ•°æ® (ç¼“å­˜é”®: {cache_key}) - è°ƒç”¨æ¥æº: {caller_info}")
                print(f"ğŸ“¦ ç¼“å­˜æ•°æ®æ¡æ•°: {len(cached_data)}")
                return self._convert_to_dataframe(cached_data)
        
        # æ£€æŸ¥æ˜¯å¦å¯ä»¥æ›´æ–°ç¼“å­˜
        if not self._can_update_cache(cache_key):
            cached_data = self._get_cached_data(cache_key)
            if cached_data is not None:
                print(f"â° ç¼“å­˜æ›´æ–°é—´éš”æœªåˆ°ï¼Œä½¿ç”¨ç°æœ‰ç¼“å­˜æ•°æ® - è°ƒç”¨æ¥æº: {caller_info}")
                print(f"â° ç¼“å­˜æ•°æ®æ¡æ•°: {len(cached_data)}")
                return self._convert_to_dataframe(cached_data)
        
        try:
            print(f" æ­£åœ¨è·å–Binanceåˆçº¦çœŸå®å†å²æ•°æ®... - è°ƒç”¨æ¥æº: {caller_info}")
            
            # ä½¿ç”¨ç»Ÿä¸€çš„æ—¶åŒºå¤„ç†å™¨è§£ææ—¥æœŸ
            start_datetime = self.tz_handler.parse_datetime(start_date, default_hour=0, default_minute=0, default_second=0)
            
            # å¤„ç†ç»“æŸæ—¥æœŸ
            if " " in end_date:  # åŒ…å«æ—¶é—´ä¿¡æ¯
                end_datetime = self.tz_handler.parse_datetime(end_date)
                # ä¸ºäº†ç¡®ä¿åŒ…å«ç›®æ ‡æ—¶é—´ç‚¹ï¼Œå°†ç»“æŸæ—¶é—´å»¶é•¿1å°æ—¶
                end_datetime = end_datetime + timedelta(hours=1)
            else:  # åªæœ‰æ—¥æœŸä¿¡æ¯
                end_datetime = self.tz_handler.parse_datetime(end_date, default_hour=23, default_minute=59, default_second=59)
            
            # è½¬æ¢ä¸ºUTCæ—¶é—´æˆ³
            start_timestamp = self.tz_handler.to_utc_timestamp(start_datetime)
            end_timestamp = self.tz_handler.to_utc_timestamp(end_datetime)
            
            # éªŒè¯æ—¶é—´èŒƒå›´åˆç†æ€§
            start_timestamp, end_timestamp = self.tz_handler.validate_time_range(
                start_timestamp, 
                end_timestamp, 
                max_days_back=BACKTEST_CONFIG.get('BACKTEST_DAYS', 60)
            )
            
            # æ˜¾ç¤ºé¦™æ¸¯æ—¶é—´èŒƒå›´
            start_hk = self.tz_handler.from_utc_timestamp(start_timestamp)
            end_hk = self.tz_handler.from_utc_timestamp(end_timestamp)
            print(f"ğŸ“… å®é™…è¯·æ±‚æ—¶é—´èŒƒå›´: {self.tz_handler.format_datetime_for_display(start_hk)} è‡³ {self.tz_handler.format_datetime_for_display(end_hk)} (é¦™æ¸¯æ—¶é—´)")
            
            # åˆ†é¡µè·å–å®Œæ•´æ•°æ®
            all_klines = []
            current_start = start_timestamp
            page_count = 0
            
            while current_start < end_timestamp and page_count < 100:  # å¢åŠ æœ€å¤§é¡µæ•°é™åˆ¶ï¼Œæ”¯æŒæ›´é•¿æ—¶é—´èŒƒå›´
                try:
                    params = {
                        "symbol": self.symbol,
                        "interval": self.timeframe,
                        "startTime": current_start,
                        "endTime": end_timestamp,
                        "limit": 1000  # Binance APIæœ€å¤§é™åˆ¶
                    }
                
                    print(f" ğŸ“¡ æ­£åœ¨è·å–ç¬¬ {page_count + 1} é¡µåˆçº¦æ•°æ®...")
                    klines_data = self._make_request("/klines", params)
                    
                    if klines_data is None:
                        print(" è·å–åˆçº¦æ•°æ®å¤±è´¥")
                        raise ConnectionError("æ— æ³•ä»åˆçº¦APIè·å–æ•°æ®")
                    
                    if not klines_data:  # æ²¡æœ‰æ›´å¤šæ•°æ®
                        print(" æ•°æ®è·å–å®Œæˆ")
                        break
                        
                    # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼å¹¶æ·»åŠ åˆ°æ€»åˆ—è¡¨
                    for kline in klines_data:
                        all_klines.append([
                            int(kline[0]),  # æ—¶é—´æˆ³
                            float(kline[1]),  # open
                            float(kline[2]),  # high
                            float(kline[3]),  # low
                            float(kline[4]),  # close
                            float(kline[5])   # volume
                        ])
                    
                    # æ›´æ–°ä¸‹ä¸€æ¬¡è¯·æ±‚çš„å¼€å§‹æ—¶é—´
                    if klines_data:
                        current_start = int(klines_data[-1][0]) + 1
                    else:
                        break
                    
                    page_count += 1
                    print(f"å·²è·å– {len(all_klines)} æ¡æ•°æ®...")
                    
                    # æ·»åŠ çŸ­æš‚å»¶è¿Ÿé¿å…APIé™åˆ¶
                    time.sleep(0.1)
                    
                except KeyboardInterrupt:
                    print("\nâš  ç”¨æˆ·ä¸­æ–­æ•°æ®è·å–")
                    raise KeyboardInterrupt("ç”¨æˆ·ä¸­æ–­æ•°æ®è·å–")
                except Exception as e:
                    print(f"è·å–ç¬¬ {page_count + 1} é¡µæ•°æ®å¤±è´¥: {e}")
                    raise e
            
            if all_klines:
                print(f"æˆåŠŸè·å– {len(all_klines)} æ¡åˆçº¦å†å²æ•°æ®")
                
                # è¿‡æ»¤æ•°æ®ï¼Œåªä¿ç•™åˆ°ç›®æ ‡æ—¶é—´ç‚¹çš„æ•°æ®
                if " " in end_date:  # å¦‚æœæŒ‡å®šäº†å…·ä½“æ—¶é—´
                    try:
                        # ä½¿ç”¨ç»Ÿä¸€çš„æ—¶åŒºå¤„ç†å™¨å¤„ç†ç›®æ ‡æ—¶é—´
                        target_end_time = self.tz_handler.parse_datetime(end_date)
                        target_end_timestamp = self.tz_handler.to_utc_timestamp(target_end_time)
                        
                        # è¿‡æ»¤æ‰è¶…è¿‡ç›®æ ‡æ—¶é—´çš„æ•°æ®
                        filtered_klines = [kline for kline in all_klines if kline[0] <= target_end_timestamp]
                        if len(filtered_klines) != len(all_klines):
                            print(f" è¿‡æ»¤åä¿ç•™ {len(filtered_klines)} æ¡æ•°æ® (ç›®æ ‡æ—¶é—´: {self.tz_handler.format_datetime_for_display(target_end_time)} é¦™æ¸¯æ—¶é—´)")
                        klines = filtered_klines
                    except Exception as e:
                        print(f"æ—¶é—´è¿‡æ»¤å¤±è´¥ï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®: {e}")
                        klines = all_klines
                else:
                    klines = all_klines
            else:
                print(" æœªè·å–åˆ°ä»»ä½•åˆçº¦æ•°æ®")
                raise ValueError("æœªè·å–åˆ°ä»»ä½•åˆçº¦å†å²æ•°æ®")
            
        except Exception as e:
            print(f"è·å–åˆçº¦å†å²æ•°æ®å¤±è´¥: {e}")
            raise e
        
        # è½¬æ¢ä¸º DataFrame å¹¶æ ¼å¼åŒ–
        df = pd.DataFrame(
            klines,
            columns=["timestamp", "open", "high", "low", "close", "volume"]
        )
        
        # éªŒè¯æ—¶é—´æˆ³çš„æœ‰æ•ˆæ€§
        if df.empty:
            print("è­¦å‘Š: æ•°æ®ä¸ºç©º")
            return df
        
        # å°†UTCæ—¶é—´æˆ³è½¬æ¢ä¸ºé¦™æ¸¯æ—¶é—´ - ç»Ÿä¸€æ—¶åŒºå¤„ç†
        df["datetime"] = pd.to_datetime(df["timestamp"], unit="ms", utc=True).dt.tz_convert(self.tz_handler.hk_tz)
        
        # éªŒè¯æ—¶åŒºè½¬æ¢ç»“æœ
        if df["datetime"].isna().any():
            print("è­¦å‘Š: éƒ¨åˆ†æ—¶é—´æˆ³è½¬æ¢å¤±è´¥")
        
        df = df.set_index("datetime").drop(columns=["timestamp"])
        
        # æ˜¾ç¤ºæ•°æ®æ—¶é—´èŒƒå›´
        if not df.empty:
            print(f"æ•°æ®æ—¶é—´èŒƒå›´: {df.index.min()} è‡³ {df.index.max()} (é¦™æ¸¯æ—¶é—´)")
        
        # æ›´æ–°ç¼“å­˜
        if all_klines:
            # å°†DataFrameè½¬æ¢å›åˆ—è¡¨æ ¼å¼ç”¨äºç¼“å­˜
            cached_data = df.reset_index().values.tolist()
            self._update_cache(cache_key, cached_data)
            print(f"ğŸ’¾ æ•°æ®å·²ç¼“å­˜ (ç¼“å­˜é”®: {cache_key})")
            print(f"ğŸ’¾ ç¼“å­˜æ•°æ®æ¡æ•°: {len(cached_data)}")
            print(f"ğŸ’¾ ç¼“å­˜æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())}")
        
        return df.astype(float)  # ç¡®ä¿æ•°å€¼ç±»å‹æ­£ç¡®
    
    def get_current_timestamp(self):
        """
        è·å–å½“å‰UTCæ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
        
        Returns:
            int: å½“å‰UTCæ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
        """
        return self.tz_handler.get_current_utc_timestamp()
    
    def test_timezone_handling(self):
        """
        æµ‹è¯•æ—¶åŒºå¤„ç†åŠŸèƒ½
        
        Returns:
            dict: æµ‹è¯•ç»“æœ
        """
        try:
            print("ğŸ§ª æµ‹è¯•æ—¶åŒºå¤„ç†åŠŸèƒ½...")
            
            # æµ‹è¯•1: è§£æä¸åŒæ ¼å¼çš„æ—¥æœŸ
            test_cases = [
                "2025-01-15",
                "2025-01-15 14:30:00",
                "2025-01-15 23:59:59"
            ]
            
            results = {}
            for test_date in test_cases:
                try:
                    parsed = self.tz_handler.parse_datetime(test_date)
                    timestamp = self.tz_handler.to_utc_timestamp(parsed)
                    converted_back = self.tz_handler.from_utc_timestamp(timestamp)
                    formatted = self.tz_handler.format_datetime_for_display(converted_back)
                    
                    results[test_date] = {
                        'parsed': str(parsed),
                        'timestamp': timestamp,
                        'converted_back': str(converted_back),
                        'formatted': formatted,
                        'success': True
                    }
                except Exception as e:
                    results[test_date] = {
                        'error': str(e),
                        'success': False
                    }
            
            # æµ‹è¯•2: æ—¶é—´èŒƒå›´éªŒè¯
            current_time = self.tz_handler.get_current_utc_timestamp()
            future_time = current_time + (24 * 60 * 60 * 1000)  # æœªæ¥1å¤©
            past_time = current_time - (24 * 60 * 60 * 1000)    # è¿‡å»1å¤©
            
            try:
                validated_start, validated_end = self.tz_handler.validate_time_range(
                    future_time, future_time + 1000, max_days_back=30
                )
                results['time_validation'] = {
                    'future_time_adjusted': True,
                    'validated_start': validated_start,
                    'validated_end': validated_end,
                    'success': True
                }
            except Exception as e:
                results['time_validation'] = {
                    'error': str(e),
                    'success': False
                }
            
            # æµ‹è¯•3: å½“å‰æ—¶é—´è·å–
            current_hk = self.tz_handler.get_current_hk_time()
            current_utc_ts = self.tz_handler.get_current_utc_timestamp()
            
            results['current_time'] = {
                'hk_time': str(current_hk),
                'utc_timestamp': current_utc_ts,
                'formatted_hk': self.tz_handler.format_datetime_for_display(current_hk),
                'success': True
            }
            
            print(" æ—¶åŒºå¤„ç†æµ‹è¯•å®Œæˆ")
            return results
            
        except Exception as e:
            print(f"æ—¶åŒºå¤„ç†æµ‹è¯•å¤±è´¥: {e}")
            return {'error': str(e), 'success': False}
    
    def get_fear_greed_index(self, date=None):
        """
        è·å–ææƒ§è´ªå©ªæŒ‡æ•°
        
        Args:
            date: æŒ‡å®šæ—¥æœŸï¼Œæ ¼å¼ä¸º 'YYYY-MM-DD'ï¼Œé»˜è®¤ä¸ºå½“å‰æ—¥æœŸ
            
        Returns:
            dict: åŒ…å«è´ªå©ªæŒ‡æ•°ä¿¡æ¯çš„å­—å…¸
        """
        try:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥æœŸï¼Œä½¿ç”¨å½“å‰æ—¥æœŸ
            if date is None:
                date = self.tz_handler.get_current_hk_time().strftime('%Y-%m-%d')
            
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"fear_greed_{date}"
            current_time = time.time()
            
            if cache_key in self.fear_greed_cache:
                cache_data = self.fear_greed_cache[cache_key]
                if current_time - cache_data['timestamp'] < self.fear_greed_cache_timeout:
                    return cache_data['data']
            
            # ä» Alternative.me API è·å–æ•°æ®
            url = "https://api.alternative.me/fng/"
            params = {
                'limit': 1,
                'format': 'json'
            }
            
            # å¦‚æœæŒ‡å®šäº†æ—¥æœŸï¼Œæ·»åŠ æ—¥æœŸå‚æ•°
            if date:
                try:
                    # å°†æ—¥æœŸè½¬æ¢ä¸ºæ—¶é—´æˆ³
                    date_obj = datetime.strptime(date, '%Y-%m-%d')
                    timestamp = int(date_obj.timestamp())
                    params['date'] = timestamp
                    print(f"ğŸ“… è¯·æ±‚æŒ‡å®šæ—¥æœŸçš„è´ªå©ªæŒ‡æ•°: {date} (æ—¶é—´æˆ³: {timestamp})")
                except ValueError as e:
                    print(f"æ—¥æœŸæ ¼å¼é”™è¯¯: {e}")
                    # å¦‚æœæ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨å½“å‰æ—¥æœŸ
                    date = datetime.now().strftime('%Y-%m-%d')
            
            print(f"ğŸ” æ­£åœ¨è·å–è´ªå©ªæŒ‡æ•°æ•°æ®...")
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                if data.get('data') and len(data['data']) > 0:
                    latest = data['data'][0]
                    
                    # æ ¹æ®å¤–éƒ¨æ•°æ®ç¡®å®šè´ªå©ªç¨‹åº¦ï¼ˆæŒ‰ç…§å›¾ç‰‡æ ‡å‡†ï¼‰
                    external_value = int(latest['value'])
                    if external_value > 75:
                        greed_level = 1.0  # æåº¦è´ªå©ª (76-100)
                    elif external_value > 55:
                        greed_level = 0.8  # è´ªå©ª (56-75)
                    elif external_value > 45:
                        greed_level = 0.6  # ä¸­æ€§ (46-55)
                    elif external_value > 25:
                        greed_level = 0.4  # ææƒ§ (26-45)
                    else:
                        greed_level = 0.2  # æåº¦ææƒ§ (0-25)
                    
                    fear_greed_data = {
                        'value': external_value,
                        'classification': latest['value_classification'],
                        'greed_level': greed_level,
                        'timestamp': latest['timestamp'],
                        'date': date
                    }
                    
                    # ç¼“å­˜æ•°æ®
                    self.fear_greed_cache[cache_key] = {
                        'data': fear_greed_data,
                        'timestamp': current_time
                    }
                    
                    print(f"è´ªå©ªæŒ‡æ•°: {fear_greed_data['value']} ({fear_greed_data['classification']})")
                    return fear_greed_data
                else:
                    print("è´ªå©ªæŒ‡æ•°æ•°æ®æ ¼å¼å¼‚å¸¸")
                    return self._get_default_fear_greed()
            else:
                print(f"è´ªå©ªæŒ‡æ•°APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                return self._get_default_fear_greed()
                
        except Exception as e:
            print(f"è·å–è´ªå©ªæŒ‡æ•°å¤±è´¥: {e}")
            return self._get_default_fear_greed()
    
    def _get_default_fear_greed(self):
        """è·å–é»˜è®¤è´ªå©ªæŒ‡æ•°ï¼ˆå½“APIä¸å¯ç”¨æ—¶ï¼‰"""
        return {
            'value': 50,
            'classification': 'Neutral',
            'greed_level': 0.6,  # ä¸­æ€§
            'timestamp': str(int(time.time())),
            'date': self.tz_handler.get_current_hk_time().strftime('%Y-%m-%d')
        }
    
    def get_vix_fear_index(self, date=None):
        """
        è·å–VIXææ…ŒæŒ‡æ•°
        
        Args:
            date: æŒ‡å®šæ—¥æœŸï¼Œæ ¼å¼ä¸º 'YYYY-MM-DD'ï¼Œé»˜è®¤ä¸ºå½“å‰æ—¥æœŸ
            
        Returns:
            dict: åŒ…å«VIXææ…ŒæŒ‡æ•°ä¿¡æ¯çš„å­—å…¸
        """
        try:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥æœŸï¼Œä½¿ç”¨å½“å‰æ—¥æœŸ
            if date is None:
                date = self.tz_handler.get_current_hk_time().strftime('%Y-%m-%d')
            
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"vix_fear_{date}"
            current_time = time.time()
            
            if cache_key in self.fear_greed_cache:
                cache_data = self.fear_greed_cache[cache_key]
                if current_time - cache_data['timestamp'] < self.fear_greed_cache_timeout:
                    return cache_data['data']
            
            # æ ¹æ®æ—¥æœŸç”Ÿæˆä¸åŒçš„æ¨¡æ‹ŸVIXæ•°æ®
            vix_data = self._get_simulated_vix_data(date)
            
            # ç¼“å­˜æ•°æ®
            self.fear_greed_cache[cache_key] = {
                'data': vix_data,
                'timestamp': current_time
            }
            
            print(f"VIXææ…ŒæŒ‡æ•°: {vix_data['value']:.2f} ({vix_data['classification']})")
            return vix_data
                
        except Exception as e:
            print(f"è·å–VIXææ…ŒæŒ‡æ•°å¤±è´¥: {e}")
            return self._get_default_vix_fear()
    
    def _get_simulated_vix_data(self, date=None):
        """è·å–æ¨¡æ‹ŸVIXæ•°æ®ï¼ˆå®é™…é¡¹ç›®ä¸­éœ€è¦æ›¿æ¢ä¸ºçœŸå®APIï¼‰"""
        # è¿™é‡Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œå®é™…é¡¹ç›®ä¸­åº”è¯¥è°ƒç”¨çœŸå®çš„VIX API
        # ä¾‹å¦‚ï¼šAlpha Vantage API, Yahoo Finance API ç­‰
        
        # æ ¹æ®æ—¥æœŸç”Ÿæˆä¸€è‡´çš„æ¨¡æ‹ŸVIXå€¼
        import random
        if date:
            # ä½¿ç”¨æ—¥æœŸä½œä¸ºéšæœºç§å­ï¼Œç¡®ä¿åŒä¸€å¤©è¿”å›ç›¸åŒçš„å€¼
            date_obj = datetime.strptime(date, '%Y-%m-%d')
            seed = date_obj.year * 10000 + date_obj.month * 100 + date_obj.day
            random.seed(seed)
        
        vix_value = random.uniform(15, 35)
        
        # æ ¹æ®VIXå€¼ç¡®å®šææ…Œç¨‹åº¦ï¼ˆæŒ‰ç…§å›¾ç‰‡æ ‡å‡†ï¼‰
        if vix_value > 40:
            classification = "Extreme Fear"
            fear_level = 1.0
        elif vix_value > 30:
            classification = "High Fear"
            fear_level = 0.8
        elif vix_value > 20:
            classification = "Fear"
            fear_level = 0.6
        elif vix_value > 15:
            classification = "Neutral"
            fear_level = 0.4
        else:
            classification = "Low Fear"
            fear_level = 0.2
        
        return {
            'value': round(vix_value, 2),
            'classification': classification,
            'fear_level': fear_level,
            'timestamp': str(int(time.time())),
            'date': self.tz_handler.get_current_hk_time().strftime('%Y-%m-%d')
        }
    
    def _get_default_vix_fear(self):
        """è·å–é»˜è®¤VIXææ…ŒæŒ‡æ•°ï¼ˆå½“APIä¸å¯ç”¨æ—¶ï¼‰"""
        return {
            'value': 20.0,
            'classification': 'Neutral',
            'fear_level': 0.4,
            'timestamp': str(int(time.time())),
            'date': self.tz_handler.get_current_hk_time().strftime('%Y-%m-%d')
        }
    
    def get_timeframe_data(self, timeframe, start_date=None, end_date=None, limit=1000):
        """
        è·å–æŒ‡å®šæ—¶é—´çº§åˆ«çš„Kçº¿æ•°æ®
        
        Args:
            timeframe: æ—¶é—´çº§åˆ« ('1h', '4h', '1d' ç­‰)
            start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ä¸º 'YYYY-MM-DD' æˆ– 'YYYY-MM-DD HH:MM:SS'
            end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ä¸º 'YYYY-MM-DD' æˆ– 'YYYY-MM-DD HH:MM:SS'
            limit: æ•°æ®æ¡æ•°é™åˆ¶
            
        Returns:
            DataFrame: Kçº¿æ•°æ®
        """
        try:
            print(f"ğŸ“¡ æ­£åœ¨è·å– {timeframe} æ—¶é—´çº§åˆ«æ•°æ®...")
            
            # éªŒè¯æ—¶é—´çº§åˆ«
            if timeframe not in self.timeframe_mapping.values():
                raise ValueError(f"ä¸æ”¯æŒçš„æ—¶é—´çº§åˆ«: {timeframe}")
            
            # è®¾ç½®é»˜è®¤æ—¶é—´èŒƒå›´
            if end_date is None:
                # ä½¿ç”¨å½“å‰æ—¶é—´ï¼Œä½†ç¡®ä¿ä¸è¶…è¿‡å½“å‰æ—¶é—´
                current_time = self.tz_handler.get_current_hk_time()
                end_date = self.tz_handler.format_datetime_for_display(current_time)
            
            if start_date is None:
                # æ ¹æ®æ—¶é—´çº§åˆ«è®¡ç®—åˆé€‚çš„å¼€å§‹æ—¶é—´
                # é™åˆ¶å†å²æ•°æ®èŒƒå›´ï¼Œé¿å…è¶…å‡ºAPIé™åˆ¶
                if timeframe == '1h':
                    start_time = current_time - timedelta(days=180)
                elif timeframe == '2h':
                    # 2å°æ—¶æ•°æ®åº”è¯¥ä¸1å°æ—¶æ•°æ®ä½¿ç”¨ç›¸åŒçš„æ—¶é—´èŒƒå›´
                    start_time = current_time - timedelta(days=180)
                elif timeframe == '4h':
                    # 4å°æ—¶æ•°æ®åº”è¯¥ä¸1å°æ—¶æ•°æ®ä½¿ç”¨ç›¸åŒçš„æ—¶é—´èŒƒå›´
                    start_time = current_time - timedelta(days=180)
                elif timeframe == '1d':
                    start_time = current_time - timedelta(days=365)  # å‡å°‘åˆ°365å¤©
                else:
                    start_time = current_time - timedelta(days=180)
                start_date = self.tz_handler.format_datetime_for_display(start_time)
            
            # ä½¿ç”¨ç»Ÿä¸€çš„æ—¶åŒºå¤„ç†å™¨è½¬æ¢æ—¶é—´æ ¼å¼
            start_time = self.tz_handler.parse_datetime(start_date)
            start_timestamp = self.tz_handler.to_utc_timestamp(start_time)
            
            end_time = self.tz_handler.parse_datetime(end_date)
            end_timestamp = self.tz_handler.to_utc_timestamp(end_time)
            
            # è°ƒè¯•æ—¶é—´æˆ³è½¬æ¢ï¼ˆä»…åœ¨éœ€è¦æ—¶æ˜¾ç¤ºï¼‰
            if DEBUG_CONFIG["SHOW_API_URLS"]:
                print(f"ğŸ” 4å°æ—¶æ•°æ®æ—¶é—´æˆ³è°ƒè¯•:")
                print(f" - start_date: {start_date}")
                print(f" - end_date: {end_date}")
                print(f" - start_time: {start_time}")
                print(f" - end_time: {end_time}")
                print(f" - start_timestamp: {start_timestamp}")
                print(f" - end_timestamp: {end_timestamp}")
            
            # éªŒè¯æ—¶é—´èŒƒå›´åˆç†æ€§
            # æ ¹æ®æ—¶é—´çº§åˆ«è°ƒæ•´æœ€å¤§å†å²å¤©æ•°
            if timeframe == '1h':
                max_days = 180
            elif timeframe == '4h':
                max_days = 180
            elif timeframe == '1d':
                max_days = 365
            else:
                max_days = 180
                
            start_timestamp, end_timestamp = self.tz_handler.validate_time_range(
                start_timestamp, 
                end_timestamp, 
                max_days_back=max_days
            )
            
            # æ„å»ºAPIè¯·æ±‚å‚æ•°
            params = {
                'symbol': self.symbol,
                'interval': timeframe,
                'startTime': start_timestamp,
                'endTime': end_timestamp,
                'limit': limit
            }
            
            # å‘é€è¯·æ±‚
            endpoint = self.api_endpoints[0]
            url = "/klines"
            
            if DEBUG_CONFIG["SHOW_API_URLS"]:
                print(f"ğŸŒ è¯·æ±‚ {timeframe} æ•°æ® URL: {endpoint}{url}")
                print(f"ğŸ“‹ è¯·æ±‚å‚æ•°: {params}")
            
            response_data = self._make_request(url, params)
            
            if not response_data:
                print(f"æœªè·å–åˆ° {timeframe} æ—¶é—´çº§åˆ«æ•°æ®")
                return pd.DataFrame()
            
            # è½¬æ¢ä¸ºDataFrame - å¤„ç†ä¸åŒåˆ—æ•°çš„å“åº”
            if response_data and len(response_data) > 0:
                # æ£€æŸ¥ç¬¬ä¸€è¡Œæ•°æ®çš„åˆ—æ•°
                first_row = response_data[0]
                if len(first_row) >= 6:
                    # æ ‡å‡†Kçº¿æ•°æ®æ ¼å¼
                    df = pd.DataFrame(
                        response_data,
                        columns=["timestamp", "open", "high", "low", "close", "volume", "close_time", "quote_volume", "trades", "taker_buy_base", "taker_buy_quote", "ignore"]
                    )
                    # åªä¿ç•™éœ€è¦çš„åˆ—
                    df = df[["timestamp", "open", "high", "low", "close", "volume"]]
                else:
                    print(f"å“åº”æ•°æ®æ ¼å¼å¼‚å¸¸ï¼Œåˆ—æ•°: {len(first_row)}")
                    return pd.DataFrame()
            else:
                print(f"å“åº”æ•°æ®ä¸ºç©º")
                return pd.DataFrame()
            
            # è½¬æ¢æ—¶é—´æˆ³
            df["datetime"] = pd.to_datetime(df["timestamp"], unit="ms", utc=True).dt.tz_convert(self.tz_handler.hk_tz)
            df = df.set_index("datetime").drop(columns=["timestamp"])
            
            print(f"æˆåŠŸè·å– {len(df)} æ¡ {timeframe} æ—¶é—´çº§åˆ«æ•°æ®")
            print(f"æ—¶é—´èŒƒå›´: {df.index.min()} è‡³ {df.index.max()} (é¦™æ¸¯æ—¶é—´)")
            
            return df.astype(float)
            
        except Exception as e:
            print(f"è·å– {timeframe} æ—¶é—´çº§åˆ«æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()